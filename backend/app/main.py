from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse, FileResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
import os
import logging
import requests
from typing import Optional, List, Dict

# Delay heavy imports until needed
# from app.vector_db import MathKnowledgeBase
# from app.langgraph_workflow import MathRAGWorkflow
from app.guardrails import AIGateway, ValidationResult
from app.feedback import get_hitl_system

load_dotenv()

# Only Perplexity API now
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# FastAPI Backend - Agentic RAG Math Agent
app = FastAPI(title="Agentic RAG Math Agent", version="1.0.0")

# Persistent user session store
import json
user_sessions_path = os.path.join(os.path.dirname(__file__), '../kb/user_sessions.json')
try:
    with open(user_sessions_path, 'r', encoding='utf-8') as f:
        user_sessions = json.load(f)
except Exception:
    user_sessions = {}

def save_user_sessions():
    with open(user_sessions_path, 'w', encoding='utf-8') as f:
        json.dump(user_sessions, f, indent=2)

# CORS middleware for frontend
origins = [
    "https://math-focused-assistant-36e20.web.app",
    "http://localhost:3000",
    "http://127.0.0.1:3000",
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Serve static files from backend directory
static_dir = os.path.join(os.path.dirname(__file__), "..")
app.mount("/static", StaticFiles(directory=static_dir), name="static")

# Health endpoint for Cloud Run / Docker health checks
@app.get("/health")
def health():
    return {"status": "ok", "service": "math-backend", "version": app.version}

# Serve frontend static files (React build)
frontend_build_dir = os.path.join(os.path.dirname(__file__), "../../frontend/build")
if os.path.exists(frontend_build_dir):
    app.mount("/app", StaticFiles(directory=frontend_build_dir), name="frontend")
    logger.info(f"Frontend build directory mounted at /app from {frontend_build_dir}")
else:
    logger.warning(f"Frontend build directory not found at {frontend_build_dir}")

# Admin endpoint to view user session data
@app.get("/admin/sessions")
def get_admin_sessions():
    return user_sessions

# Initialize components - delay heavy initialization
kb = None  # Will be initialized on first request
workflow = None  # LangGraph workflow will be initialized after startup
ai_gateway = AIGateway()
hitl_system = get_hitl_system()

class Query(BaseModel):
    question: str
    difficulty: Optional[str] = "JEE_Main"  # JEE_Main or JEE_Advanced
    topic: Optional[str] = None

def query_perplexity_api(question: str) -> str:
    """Query Perplexity API for web search and answer generation"""
    if not PERPLEXITY_API_KEY:
        logger.error("Perplexity API key is missing.")
        return "Perplexity API key is missing."
    
    try:
        # Perplexity API endpoint
        url = "https://api.perplexity.ai/chat/completions"
        
        payload = {
            "model": "sonar",  # Correct Perplexity model name
            "messages": [
                {
                    "role": "system",
                    "content": "You are an expert mathematics tutor. Provide a detailed step-by-step solution to the given math problem."
                },
                {
                    "role": "user",
                    "content": f"Solve this math problem with step-by-step explanation:\n\n{question}"
                }
            ],
            "temperature": 0.2,
            "max_tokens": 1000
        }
        
        headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # Allow longer timeout for web-search model (Perplexity) calls
        response = requests.post(url, json=payload, headers=headers, timeout=120)
        response.raise_for_status()
        
        result = response.json()
        
        # Extract answer from Perplexity response
        if "choices" in result and len(result["choices"]) > 0:
            answer = result["choices"][0]["message"]["content"]
            
            # Check if citations are available
            citations = result.get("citations", [])
            if citations:
                answer += "\n\nðŸ“š Sources:\n" + "\n".join(f"- {cite}" for cite in citations[:3])
            
            return answer
        else:
            return "No answer generated by Perplexity"
            
    except requests.RequestException as e:
        logger.error(f"Perplexity API request failed: {e}")
        # FALLBACK: Return helpful error message
        logger.warning("Perplexity API unavailable - question not found in knowledge base")
        return f"""**Web Search Unavailable**

Question: {question}

Unfortunately, this question is not in our knowledge base and the Perplexity web search API is currently unavailable.

**Possible reasons:**
- API key may need renewal at https://www.perplexity.ai/settings/api
- Model name may have changed (current: llama-3.1-sonar-small-128k)
- API quota may be exceeded

**Recommendation:** Please try:
1. Questions that match our knowledge base topics (Calculus, Algebra, Probability)
2. Verifying API credentials
3. Checking Perplexity API documentation for current model names

*This is a demonstration system. For production use, ensure API keys are valid.*"""
    except Exception as e:
        logger.error(f"Perplexity API error: {e}")
        return f"Error processing Perplexity response: {str(e)}"

@app.on_event("startup")
async def startup_event():
    """Initialize app - delayed heavy initialization for Render deployment"""
    global workflow
    
    logger.info("ðŸš€ FastAPI server starting...")
    logger.info("âš ï¸  Heavy initialization (KB & LangGraph) will happen on first request")
    logger.info("âœ… Server is ready to accept connections")

async def lazy_init():
    """Lazy initialization of KB and workflow - called on first request"""
    global workflow, kb
    
    if workflow is not None and kb is not None:
        return  # Already initialized
    
    logger.info("ðŸ”„ Starting lazy initialization of knowledge base and workflow...")
    
    # Import heavy modules only when needed
    from app.vector_db import MathKnowledgeBase
    from app.langgraph_workflow import MathRAGWorkflow
    
    # Initialize knowledge base first
    if kb is None:
        logger.info("Initializing MathKnowledgeBase...")
        kb = MathKnowledgeBase()
    
    # Sample problems for testing
    sample_problems = [
        {
            "problem_id": "calc_001",
            "question": "Evaluate the integral âˆ«â‚€Â¹ xÂ² ln(x) dx using integration by parts",
            "solution_steps": [
                "Use integration by parts with u = ln(x) and dv = xÂ² dx",
                "Then du = (1/x)dx and v = xÂ³/3",
                "Apply the formula: âˆ«u dv = uv - âˆ«v du",
                "This gives: [xÂ³ln(x)/3]â‚€Â¹ - âˆ«â‚€Â¹ (xÂ³/3)(1/x) dx",
                "Simplify: [xÂ³ln(x)/3]â‚€Â¹ - âˆ«â‚€Â¹ xÂ²/3 dx",
                "Evaluate limits and integral: 0 - [xÂ³/9]â‚€Â¹ = -1/9"
            ],
            "final_answer": "-1/9",
            "difficulty": "JEE_Advanced",
            "tags": ["integration", "integration_by_parts", "logarithm"],
            "topic": "Calculus"
        },
        {
            "problem_id": "alg_001",
            "question": "Solve for x: xÂ³ - 3x + 2 = 0",
            "solution_steps": [
                "Try to factor the cubic equation",
                "Test x = 1: 1Â³ - 3(1) + 2 = 0 âœ“",
                "So (x - 1) is a factor",
                "Perform polynomial division: (xÂ³ - 3x + 2) Ã· (x - 1) = xÂ² + x - 2",
                "Factor the quadratic: xÂ² + x - 2 = (x + 2)(x - 1)",
                "Therefore: (x - 1)(x + 2)(x - 1) = (x - 1)Â²(x + 2) = 0",
                "Solutions: x = 1 (double root) and x = -2"
            ],
            "final_answer": "x = 1 (multiplicity 2), x = -2",
            "difficulty": "JEE_Main",
            "tags": ["polynomial", "cubic_equation", "factorization"],
            "topic": "Algebra"
        },
        {
            "problem_id": "calc_004",
            "question": "Find the derivative of f(x) = x^x for x > 0",
            "solution_steps": [
                "Take natural logarithm of both sides: ln(f(x)) = ln(x^x) = x ln(x)",
                "Differentiate both sides using implicit differentiation",
                "Left side: (1/f(x)) Â· f'(x)",
                "Right side: d/dx[x ln(x)] = ln(x) + xÂ·(1/x) = ln(x) + 1",
                "So: f'(x)/f(x) = ln(x) + 1",
                "Therefore: f'(x) = f(x) Â· (ln(x) + 1) = x^x Â· (ln(x) + 1)"
            ],
            "final_answer": "f'(x) = x^x(ln(x) + 1)",
            "difficulty": "JEE_Advanced",
            "tags": ["differentiation", "logarithmic_differentiation", "exponential"],
            "topic": "Calculus"
        },
        {
            "problem_id": "prob_001",
            "question": "A box contains 5 red balls and 3 blue balls. If 3 balls are drawn at random without replacement, what is the probability that exactly 2 are red?",
            "solution_steps": [
                "Total balls = 5 + 3 = 8",
                "Need to find P(exactly 2 red in 3 draws)",
                "This means 2 red and 1 blue",
                "Number of ways to choose 2 red from 5: C(5,2) = 10",
                "Number of ways to choose 1 blue from 3: C(3,1) = 3",
                "Number of ways to choose 3 from 8: C(8,3) = 56",
                "P(2 red, 1 blue) = [C(5,2) Ã— C(3,1)] / C(8,3) = (10 Ã— 3) / 56 = 30/56 = 15/28"
            ],
            "final_answer": "15/28 â‰ˆ 0.536",
            "difficulty": "JEE_Main",
            "tags": ["probability", "combinations", "without_replacement"],
            "topic": "Probability"
        },
        {
            "problem_id": "trig_001",
            "question": "Find the Maclaurin series for sin(x) up to the xâµ term",
            "solution_steps": [
                "Recall the Maclaurin series: f(x) = Î£[fâ½â¿â¾(0)/n!]xâ¿",
                "Find derivatives at x=0:",
                "  f(x) = sin(x), f(0) = 0",
                "  f'(x) = cos(x), f'(0) = 1",
                "  f''(x) = -sin(x), f''(0) = 0",
                "  f'''(x) = -cos(x), f'''(0) = -1",
                "  fâ½â´â¾(x) = sin(x), fâ½â´â¾(0) = 0",
                "  fâ½âµâ¾(x) = cos(x), fâ½âµâ¾(0) = 1",
                "Substitute into formula:",
                "sin(x) = 0 + x - 0 - xÂ³/3! + 0 + xâµ/5! + ...",
                "sin(x) = x - xÂ³/6 + xâµ/120 + ..."
            ],
            "final_answer": "sin(x) â‰ˆ x - xÂ³/6 + xâµ/120",
            "difficulty": "JEE_Advanced",
            "tags": ["series", "maclaurin_series", "trigonometry"],
            "topic": "Calculus"
        }
    ]
    
    for problem in sample_problems:
        try:
            kb.add_problem(**problem)
            logger.info(f"Added problem: {problem['problem_id']}")
        except Exception as e:
            logger.error(f"Failed to add problem {problem['problem_id']}: {e}")
    
    total = kb.count_problems()
    logger.info(f"Knowledge base initialized with {total} problems")
    
    # Initialize LangGraph workflow (only with Perplexity now)
    logger.info("Initializing LangGraph workflow...")
    workflow = MathRAGWorkflow(kb, query_perplexity_api)
    logger.info("âœ… LangGraph workflow ready!")
    logger.info("âœ… Lazy initialization complete!")

@app.get("/")
async def read_root():
    """Health check endpoint"""
    kb_count = kb.count_problems() if kb else 0
    return {
        "message": "Welcome to the Agentic RAG Math Agent Backend!",
        "status": "online",
        "version": "1.0.0",
        "langgraph": "enabled",
        "kb_initialized": kb is not None,
        "kb_count": kb_count
    }

@app.get("/kb/status")
def get_kb_status():
    """Get knowledge base statistics"""
    return {
        "total_problems": kb.count_problems(),
        "status": "ready"
    }


@app.post("/guardrails/validate")
def validate_question(query: Query) -> Dict:
    """
    Test endpoint to validate a question through guardrails without processing.
    Useful for testing and debugging guardrails.
    
    Args:
        query: Query object with question
        
    Returns:
        Detailed validation report
    """
    report = AIGateway.get_full_report(query.question)
    return report

@app.post("/query")
async def query_rag_pipeline(query: Query, request: Request) -> Dict:
    """
    Main RAG pipeline endpoint with AI Gateway guardrails
    
    AI Gateway Flow:
    1. Input Guardrails â†’ Validate question is math-related
    2. LangGraph Workflow â†’ Process query if approved
    3. Output Guardrails â†’ Validate and sanitize response
    
    LangGraph Workflow:
    1. search_database â†’ Check KB for similar problems
    2. Decision: Found? â†’ gemini_analyze | Not found? â†’ web_search
    3. gemini_analyze â†’ Gemini analyzes DB data â†’ END
    4. web_search â†’ Perplexity searches web
    5. Decision: Found on web? â†’ END | Not found? â†’ not_found
    6. not_found â†’ Return "NOT FOUND" â†’ END
    """
    # Identify user (for demo, use IP address; in production, use proper auth/session)
    user_id = request.client.host
    if user_id not in user_sessions:
        user_sessions[user_id] = {"count": 0, "logged_in": False}
        save_user_sessions()
    session = user_sessions[user_id]

    # Check if login is required
    if session["count"] >= 10 and not session["logged_in"]:
        save_user_sessions()
        return JSONResponse(status_code=401, content={"error": "Login required after 10 questions."})

    logger.info(f"Received query: {query.question}")
    
    # ============================================
    # STEP 1: INPUT GUARDRAILS
    # ============================================
    input_validation = AIGateway.process_query(query.question)

    if not input_validation['approved']:
        logger.warning(f"Query rejected by input guardrails: {input_validation['message']}")
        session["count"] += 1
        save_user_sessions()
        return {
            "error": "Input validation failed",
            "message": input_validation['message'],
            "answer": "â›” Your question was blocked by safety guardrails. Please ensure your question is math-related and appropriate.",
            "confidence": "none",
            "confidence_score": 0.0,
            "source": "guardrails_rejected",
            "guardrails": {
                "input_validation": input_validation['result'],
                "input_message": input_validation['message']
            }
        }
    
    # Input approved with warning (borderline math question)
    if input_validation['result'] == 'warning':
        logger.info(f"Query approved with warning: {input_validation['message']}")
    else:
        logger.info(f"Input approved")
    
    session["count"] += 1
    save_user_sessions()
    
    # ============================================
    # STEP 1.5: LAZY INITIALIZATION
    # ============================================
    await lazy_init()  # Initialize KB and workflow on first request
    
    # ============================================
    # STEP 2: LANGGRAPH WORKFLOW
    # ============================================
    if workflow is None:
        return {
            "error": "Workflow not initialized",
            "answer": "System is still initializing, please try again in a few seconds",
            "confidence": "none",
            "confidence_score": 0.0,
            "source": "error"
        }
    
    try:
        # Run the LangGraph workflow
        final_state = workflow.run(query.question, query.difficulty)
        
        # ============================================
        # STEP 3: OUTPUT GUARDRAILS
        # ============================================
        output_validation = AIGateway.process_response(
            response=final_state['final_answer'],
            question=query.question
        )
        
        # Build response from final state
        response = {
            "answer": output_validation['response'],  # Sanitized response
            "confidence": final_state['confidence'],
            "confidence_score": final_state['confidence_score'],
            "source": final_state['source'],
            "kb_results": final_state['kb_results'],
            "note": final_state['note'],
            "guardrails": {
                "input_validation": input_validation['result'],
                "input_message": input_validation['message'],
                "output_validation": output_validation['result'],
                "output_message": output_validation['message'],
                "sanitized": output_validation['approved']
            }
        }
        
        # Add warning if output has issues
        if output_validation['result'] == 'warning':
            response['warning'] = output_validation['message']
        
        # Add optional fields based on source
        if final_state['source'] == 'gemini_with_db':
            response['reasoning_steps'] = final_state['best_match'].get('solution_steps', [])
            response['matched_problem_id'] = final_state['best_match'].get('problem_id')
            response['topic'] = final_state['best_match'].get('topic')
            response['difficulty'] = final_state['best_match'].get('difficulty')
        
        if final_state['source'] == 'not_found':
            response['suggestion'] = "Please try rephrasing your question or provide more details."
        
        if final_state.get('error'):
            response['error'] = final_state['error']
        
        logger.info(f"âœ… Query processed successfully with guardrails")
        return response
        
    except Exception as e:
        logger.error(f"Error in LangGraph workflow: {e}")
        return {
            "error": str(e),
            "answer": "An error occurred processing your query",
            "confidence": "none",
            "confidence_score": 0.0,
            "source": "error"
        }


# ==================== Authentication Endpoint ====================

@app.post("/login")
async def login(request: Request):
    """User login endpoint to reset query count"""
    user_id = request.client.host
    user_sessions[user_id] = {"count": 0, "logged_in": True}
    save_user_sessions()
    return {"status": "logged_in"}


# ==================== HITL Feedback Endpoints ====================

class FeedbackRequest(BaseModel):
    """Feedback submission model"""
    question: str
    answer: str
    rating: str  # "thumbs_up" or "thumbs_down"
    correction: Optional[str] = None
    comment: Optional[str] = None
    metadata: Optional[Dict] = None


@app.post("/feedback/submit")
async def submit_feedback(feedback: FeedbackRequest):
    """
    Submit user feedback for a response
    
    Args:
        feedback: FeedbackRequest with rating and optional comments
        
    Returns:
        Confirmation of feedback submission
    """
    try:
        result = hitl_system.submit_feedback(
            question=feedback.question,
            answer=feedback.answer,
            rating=feedback.rating,
            correction=feedback.correction,
            comment=feedback.comment,
            metadata=feedback.metadata
        )
        
        logger.info(f"ðŸ“ Feedback submitted: {feedback.rating} (ID: {result['feedback_id']})")
        return result
        
    except ValueError as e:
        logger.error(f"Invalid feedback: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Error submitting feedback: {e}")
        raise HTTPException(status_code=500, detail="Failed to submit feedback")


@app.get("/feedback/stats")
async def get_feedback_stats():
    """
    Get feedback statistics
    
    Returns:
        Statistics about collected feedback
    """
    try:
        stats = hitl_system.get_statistics()
        logger.info(f"ðŸ“Š Feedback stats requested: {stats['total_feedback']} entries")
        return stats
    except Exception as e:
        logger.error(f"Error getting feedback stats: {e}")
        raise HTTPException(status_code=500, detail="Failed to get statistics")


@app.get("/feedback/improvements")
async def get_improvements():
    """
    Get AI-suggested improvements based on feedback
    
    Returns:
        Improvement suggestions and priority actions
    """
    try:
        improvements = hitl_system.get_improvements()
        logger.info(f"ðŸŽ¯ Improvement suggestions requested")
        return improvements
    except Exception as e:
        logger.error(f"Error getting improvements: {e}")
        raise HTTPException(status_code=500, detail="Failed to get improvements")


@app.get("/feedback/report")
async def get_learning_report():
    """
    Get comprehensive learning report
    
    Returns:
        Detailed report with statistics, analysis, and recommendations
    """
    try:
        report = hitl_system.get_learning_report()
        logger.info(f"ðŸ“ˆ Learning report generated")
        return report
    except Exception as e:
        logger.error(f"Error generating report: {e}")
        raise HTTPException(status_code=500, detail="Failed to generate report")


@app.get("/feedback/list")
async def list_feedback(limit: int = 50, rating: Optional[str] = None):
    """
    List recent feedback entries
    
    Args:
        limit: Maximum number of entries to return
        rating: Filter by rating (thumbs_up/thumbs_down)
        
    Returns:
        List of feedback entries
    """
    try:
        if rating:
            feedback_list = hitl_system.feedback_store.get_feedback_by_rating(rating)
        else:
            feedback_list = hitl_system.feedback_store.feedback_data
        
        # Return most recent first
        recent_feedback = sorted(
            feedback_list,
            key=lambda x: x['timestamp'],
            reverse=True
        )[:limit]
        
        logger.info(f"ðŸ“‹ Listing {len(recent_feedback)} feedback entries")
        return {
            "count": len(recent_feedback),
            "feedback": recent_feedback
        }
    except Exception as e:
        logger.error(f"Error listing feedback: {e}")
        raise HTTPException(status_code=500, detail="Failed to list feedback")


@app.get("/feedback/problem-status")
async def get_problem_status():
    """
    Get problem report status (total problems, solved, pending)

    Returns:
        Statistics about problem reports and their resolution status
    """
    try:
        all_feedback = hitl_system.feedback_store.feedback_data

        # Filter problem reports
        problem_reports = [
            fb for fb in all_feedback 
            if fb.get('metadata', {}).get('feedback_type') == 'problem_report' or 
               fb.get('question', '').startswith('[USER PROBLEM REPORT')
        ]

        # Count solved problems (those with admin response or marked as resolved)
        solved_problems = [
            pr for pr in problem_reports
            if pr.get('metadata', {}).get('status') == 'resolved' or
               pr.get('metadata', {}).get('admin_response')
        ]

        # Count pending problems
        pending_problems = [
            pr for pr in problem_reports
            if pr not in solved_problems
        ]

        # Group by problem type
        problem_types = {}
        for pr in problem_reports:
            prob_type = pr.get('metadata', {}).get('problem_type', 'other')
            if prob_type not in problem_types:
                problem_types[prob_type] = {'total': 0, 'solved': 0, 'pending': 0}
            problem_types[prob_type]['total'] += 1

            if pr in solved_problems:
                problem_types[prob_type]['solved'] += 1
            else:
                problem_types[prob_type]['pending'] += 1

        all_solved = len(problem_reports) > 0 and len(pending_problems) == 0

        logger.info(f"ðŸ“Š Problem status: {len(problem_reports)} total, {len(solved_problems)} solved, {len(pending_problems)} pending")

        return {
            "total_problems": len(problem_reports),
            "solved_problems": len(solved_problems),
            "pending_problems": len(pending_problems),
            "all_solved": all_solved,
            "solve_rate": (len(solved_problems) / len(problem_reports) * 100) if len(problem_reports) > 0 else 0,
            "by_type": problem_types,
            "recent_problems": sorted(
                problem_reports,
                key=lambda x: x.get('timestamp', ''),
                reverse=True
            )[:10]  # Last 10 problems
        }
    except Exception as e:
        logger.error(f"Error getting problem status: {e}")
        raise HTTPException(status_code=500, detail="Failed to get problem status")


# Catch-all route to serve React frontend for any unmatched route
@app.get("/{full_path:path}")
async def serve_frontend(full_path: str):
    """Serve React frontend for any path not matched by API routes"""
    frontend_index = os.path.join(os.path.dirname(__file__), "../../frontend/build/index.html")

    # If requesting a specific file that exists, serve it
    if full_path and not full_path.startswith("api"):
        requested_file = os.path.join(os.path.dirname(__file__), "../../frontend/build", full_path)
        if os.path.isfile(requested_file):
            return FileResponse(requested_file)

    # Otherwise serve index.html for React Router
    if os.path.exists(frontend_index):
        return FileResponse(frontend_index)
    else:
        return JSONResponse(
            content={
                "message": "Frontend not built. Run 'npm run build' in the frontend directory.",
                "api_status": "Backend is running",
                "api_docs": "/docs"
            },
            status_code=200
        )
